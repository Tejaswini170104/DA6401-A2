{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp1B2qVBwLNuDPrEjtE1LX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tejaswini170104/DA6401-A2/blob/main/PartB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 01**"
      ],
      "metadata": {
        "id": "rTVyOR9Q070J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (a) Adjusting Input Image Dimensions for Pretrained Models\n",
        "\n",
        "- **ImageNet pretrained models** (e.g., ResNet, VGG, EfficientNet) expect input images to have a resolution of **224×224 pixels**.\n",
        "- **iNaturalist dataset images** may have different sizes and aspect ratios.\n",
        "- To ensure compatibility with the pretrained model:\n",
        "  - **Resize** all images to match the input size expected by the model.\n",
        "  - Use the `transforms.Resize()` function in PyTorch to resize images.\n",
        "  - Additional cropping using `transforms.CenterCrop()` can be applied to focus on the central content of the image.\n",
        "- Example of resizing:\n",
        "\n",
        "  ```python\n",
        "  transforms.Resize((224, 224))  # Resize to match input size expected by most pretrained models\n",
        "  ```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### (b) Replacing the Output Layer for a 10-Class Classification Task\n",
        "\n",
        "- **Pretrained models** are designed for **ImageNet’s 1000-class classification**.\n",
        "- The iNaturalist dataset has only **10 classes**, so the output layer must be adjusted.\n",
        "- **Modification**:\n",
        "  - Replace the last fully connected (FC) layer to output 10 logits (one for each class).\n",
        "  - This ensures the model outputs the correct number of predictions for the iNaturalist task.\n",
        "- Example modification for ResNet50:\n",
        "\n",
        "  ```python\n",
        "  from torchvision import models\n",
        "  import torch.nn as nn\n",
        "\n",
        "  model = models.resnet50(pretrained=True)\n",
        "  num_features = model.fc.in_features\n",
        "  model.fc = nn.Linear(num_features, 10)  # Update final layer for 10-class output\n",
        "  ```\n",
        "\n"
      ],
      "metadata": {
        "id": "ri6JVzTdIMAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 02**"
      ],
      "metadata": {
        "id": "nQJER4jBIioG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Strategies to Make Fine-Tuning Tractable\n",
        "\n",
        "- **Freezing All Layers Except the Last Layer**:\n",
        "  - In this approach, all the layers of the model are frozen, meaning their weights remain unchanged during training. Only the final fully connected (FC) layer is trainable, allowing the model to adapt to the new task without requiring full retraining.\n",
        "  - This approach leverages the pretrained features in the earlier layers, which are generally useful for a wide range of tasks, while only training the final layer to match the specific 10-class task.\n",
        "\n",
        "  Example:\n",
        "  ```python\n",
        "  for param in model.parameters():\n",
        "      param.requires_grad = False  # Freeze all layers\n",
        "\n",
        "  # Only the last layer will be updated\n",
        "  model.fc.requires_grad = True  # Unfreeze the last FC layer\n",
        "  ```\n",
        "\n",
        "- **Freezing Layers Up to the k-th Layer**:\n",
        "  - In this strategy, the first few layers are frozen, and only the layers after a certain point (e.g., the k-th layer) are allowed to be updated. The idea here is to freeze the early layers which learn basic features (like edges and textures) that are likely transferable across different tasks, while fine-tuning the later layers to capture task-specific details.\n",
        "  - This approach is a middle ground between freezing all layers and training the entire model.\n",
        "\n",
        "  Example:\n",
        "  ```python\n",
        "  for i, param in enumerate(model.parameters()):\n",
        "      if i < k:\n",
        "          param.requires_grad = False  # Freeze layers up to k-th layer\n",
        "      else:\n",
        "          param.requires_grad = True  # Unfreeze layers after k-th layer\n",
        "  ```\n",
        "\n",
        "- **Fine-Tuning Only the Last Few Layers**:\n",
        "  - Another approach is to **fine-tune only the last few layers**, such as the final few convolutional or dense layers. The idea behind this strategy is to allow the model to adapt to the specific characteristics of the new dataset while retaining the powerful features learned by the earlier layers.\n",
        "  - In this case, the number of layers to fine-tune can be adjusted based on computational constraints and the task's complexity.\n",
        "\n",
        "  Example:\n",
        "  ```python\n",
        "  # Freezing early layers and fine-tuning the last few layers\n",
        "  for param in model.parameters():\n",
        "      param.requires_grad = False  # Freeze all layers\n",
        "\n",
        "  # Unfreeze the last 2 layers\n",
        "  for param in model.layer4.parameters():\n",
        "      param.requires_grad = True\n",
        "  ```\n"
      ],
      "metadata": {
        "id": "CT1cWEbJJbda"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qPCT40D0J90I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}